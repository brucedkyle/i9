{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I-9 Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assistant helps business vet an employee submission of an I-9 and provides next steps if the form is incomplete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business problem:\n",
    "\n",
    "The I-9 (Employment Eligibility Verification) form serves several critical business needs:\n",
    "\n",
    "Legal Compliance\n",
    "- Required by federal law for every new hire in the U.S.\n",
    "- Employers must verify both identity and employment eligibility within 3 business days of hire\n",
    "- Failure to properly complete and maintain I-9s can result in significant fines ($234-$2,332 per violation as of 2024) and potential criminal penalties\n",
    "\n",
    "Risk Management\n",
    "- Protects against hiring unauthorized workers, which can lead to:\n",
    "  - Department of Labor investigations\n",
    "  - Immigration and Customs Enforcement (ICE) audits\n",
    "  - Loss of business licenses in some jurisdictions\n",
    "  - Reputational damage\n",
    "- Creates a clear audit trail of employment eligibility verification\n",
    "\n",
    "Workplace Security\n",
    "- Helps ensure all employees are who they claim to be\n",
    "- Establishes a consistent verification process across all new hires\n",
    "- Supports overall workplace safety and security measures\n",
    "\n",
    "Business Operations\n",
    "- Required for payroll and tax documentation\n",
    "- Often needed for government contracts and certifications\n",
    "- May be necessary for business loans or corporate transactions\n",
    "- Essential for maintaining clean corporate records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install OpenAI, Tavily, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain>=0.2.0 langchain-openai>=0.1.7 langchain-community>=0.2.0 langgraph>=0.1.1 langchain-chroma>=0.1.2\n",
    "!pip install python-dotenv\n",
    "!pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "'''\n",
    "# for Colab users\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "'''\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] \n",
    "TAVILY_API_KEY = os.environ['TAVILY_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Search Index for Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the creation of the vector store, a paragraph-based chunking approach is implemented using Docling and LangChain, and the vector database is built with ChromaDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the manual that has been copied to `data/i9_instructions.pdf`. (The original can be found at https://www.uscis.gov/sites/default/files/document/forms/i-9instr.pdf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file_path = (\n",
    "    \"./data/i-9instr.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    ## TODO: add metadata about the document being loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference [PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)\n",
    "If you want to load a folder, see [Langchain Pdf Loader Multiple Files](https://www.restack.io/docs/langchain-knowledge-pdf-loader-multiple-files-cat-ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split into documents chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,\n",
    "                                                 chunk_overlap=200)\n",
    "doc_chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "doc_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vector DB and persist on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses [LangChain Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma/)\n",
    "\n",
    "If you want to use a in memory vector store, see [https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Create document embeddings and store in Vector DB\n",
    "openai_embed_model = OpenAIEmbeddings()\n",
    "\n",
    "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
    "chroma_db = Chroma.from_documents(documents=doc_chunks,\n",
    "                                  collection_name='rag_i9_db',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./i9_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add metadata with document name into Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
